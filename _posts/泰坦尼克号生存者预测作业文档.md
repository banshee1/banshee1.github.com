---
layout:     post
title:      "泰坦尼克号生存者预测"
subtitle:   "Tensorflow"
date:       2018-6-10 11:50:00
author:     "Halley"
header-img: "img/categories-bg.jpg"
catalog: true
tags:
- Machine Learning
---

# 泰坦尼克号生存者预测作业文档

1511415		樊文杰	软件工程

---



### 1.	任务描述

​            在kaggle的网站上可以下载训练数据train.csv和测试数据test.csv，利用train.csv中的乘客数据来训练自己的模型，然后预测test.csv中乘客的生存情况。



---



### 2.	实验环境

 * 语言: 	Python3.6

 * 主要使用的包:      pandas, numpy, tensorflow,sklearn

   

---



### 3.	数据分析

- **Survived**：是否存活（0代表否，1代表是）

- **Pclass**：社会阶级（1代表上层阶级，2代表中层阶级，3代表底层阶级）

- **Name**：船上乘客的名字

- **Sex**：船上乘客的性别

- **Age**:  船上乘客的年龄（可能存在 `NaN`）

- **SibSp**：乘客在船上的兄弟姐妹和配偶的数量

- **Parch**：乘客在船上的父母以及小孩的数量

- **Ticket**：乘客船票的编号

- **Fare**：乘客为船票支付的费用

- **Cabin**：乘客所在船舱的编号（可能存在 `NaN`）

- **Embarked**：乘客上船的港口（C 代表从 Cherbourg 登船，Q 代表从 Queenstown 登船，S 代表从 Southampton 登船）

  ​	以上即为train.csv中所包含的数据，其中可以看出存在部分列是无法直接用于计算的，所以我们需要对原始的数据进行加工。利用pandas.read_csv读取数据并进行统计:

  ​	

  ```python
  import os
  import numpy as np
  import pandas as pd
  import tensorflow as tf
  
  train_data = pd.read_csv('train.csv')
  print(train_data.info())
  ```

  ​	

  ​	然后就会得到以下结果:

  ```
  RangeIndex: 891 entries, 0 to 890
  Data columns (total 12 columns):
  PassengerId    891 non-null int64
  Survived       891 non-null int64
  Pclass         891 non-null int64
  Name           891 non-null object
  Sex            891 non-null object
  Age            714 non-null float64
  SibSp          891 non-null int64
  Parch          891 non-null int64
  Ticket         891 non-null object
  Fare           891 non-null float64
  Cabin          204 non-null object
  Embarked       889 non-null object
  dtypes: float64(2), int64(5), object(5)
  memory usage: 83.6+ KB
  None
  ```

  ​	数据的Cabin列缺失过于严重，所以在训练模型时选择舍掉这一列。而对于Age列，见下图：

  

<img src="C:\Users\banshee\Desktop\ML\v2-23facc53c6559952e0137e809656831f_r.jpg" width="450px" height="400px" />

​	 						图1:  性别对生存结果影响的统计图

​		由数据的统计图来看，Age列对生存结果的影响是不能忽略的，但是由于缺失量也不在少数，所以简单的用平均年龄填充空缺值可能并不是一个好的解决办法。最后选择利用随机森林算法来补全年龄的空缺值.

```python
age = dataset[['Age','Survived','Fare','Parch','SibSp','Pclass']]
age_notnull = age.loc[(dataset.Age.notnull())]
age_isnull = age.loc[(dataset.Age.isnull())]
X = age_notnull.values[:,1:]
Y = age_notnull.values[:,0]
rfr = RandomForestRegressor(n_estimators=1000,n_jobs=-1)
rfr.fit(X,Y)
predictAges = rfr.predict(age_isnull.values[:,1:])
dataset.loc[(dataset.Age.isnull()),'Age'] = predictAges
```

​		其他列的空缺选择用众数或者平均数填充。

---

### 4.	算法选择和特征处理

#### 	4.1  算法选择

​		在选择实现算法时，我主要考虑过**随机森林**和**神经网络**。经过初步的对比实验，我认为神经网络的可调		    

​	节空间更大而且初步效果比较好，所以我选择了用tensorflow搭建一个简单的network。模型图如下:

<img src="C:\Users\banshee\Desktop\ML\model.png" width="400px" height="300px" />

​		由于数据复杂度并不高，所以采用双层即可。

#### 	4.2	特征处理

​		对于特征的处理，主要有两种:

​			(1)	连续值保持不变，表示类型的值转换成one-hot-array。

​			(2)	类型值用整数标识。

​		上述两种方法，都是将训练数据转换成矩阵放入到network中。其中one-hot-array版本实现在onehot.py中，整数表示类别版本实现在titanic.py中。**而实验结果表明，one-hot-array实现的算法效果要**

**稍稍地好于映射到整数的算法。**

##### 		4.2.1	代表类型的属性

​			包括Pclass, Sex, Embarked这几列。按照上述所说，若映射到整数，则实现很简单。

​		而在转变为ont-hot-array时，则利用sklearn中封装的函数来实现:

```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X_1 = LabelEncoder()
X_train[:, 1] = labelencoder_X_1.fit_transform(X_train[:, 1])
X_train[:, 4] = labelencoder_X_1.fit_transform(X_train[:, 4])
X_train[:, 5] = labelencoder_X_1.fit_transform(X_train[:, 5])
X_train[:, 6] = labelencoder_X_1.fit_transform(X_train[:, 6])

labelencoder_X_2 = LabelEncoder()
X_test[:, 1] = labelencoder_X_2.fit_transform(X_test[:, 1])
X_test[:, 4] = labelencoder_X_2.fit_transform(X_test[:, 4])
X_test[:, 5] = labelencoder_X_2.fit_transform(X_test[:, 5])
X_test[:, 6] = labelencoder_X_2.fit_transform(X_test[:, 6])

onehotencoder = OneHotEncoder(categorical_features = [0, 1, 4, 5, 6])
X_train = onehotencoder.fit_transform(X_train).toarray()

onehotencoder = OneHotEncoder(categorical_features = [0, 1, 4, 5, 6])
X_test = onehotencoder.fit_transform(X_test).toarray()
```

#### 		4.2.2	Name属性列的处理

​			对于名字这一列，有用的信息只有中间的那个头衔。而称号对生存的影响统计如下图:

<img src="C:\Users\banshee\Desktop\ML\v2-e45fd8a37464233e23fe526671470582_r.jpg" width="400px" height="300px" />

​								图2:		头衔对存活影响的统计

​			我们可以发现，头衔对于生存概率的影响是存在的，所以根据头衔可以把乘客分为贵宾和普通人，

​		而显然贵宾的存活概率要比普通乘客要大。

#### 		4.2.3	其他属性的处理

​			在两个实现的py文件中，对以下属性进行了不同的处理:

​				在titanic.py中，SibSp和Parch是直接放入了数据中，而onhot.py中则将两者相加并根据和将

​			  乘客分为了4类:

```python
dataset["FamilyS"] = dataset["SibSp"] + dataset["Parch"] + 1
X_test["FamilyS"] = X_test["SibSp"] + X_test["Parch"] + 1

def family(x):
    if x < 2:
        return "Single"
    elif x <= 2:
        return "Couple"
    elif x <= 4:
        return "InterM"
    else:
        return "Large"
dataset["FamilyS"] = dataset["FamilyS"].apply(family)
X_test["FamilyS"] = X_test["FamilyS"].apply(family)
```

​				同时也将其编码为one-hot-array形式。而实验结果显示两者之间的差异并不大。

​			Ticket属性和Cabin属性由于难以体现乘客特征和缺失过多故舍去。

​				同时，对于y，同样转变成one-hot-label的形式，即[0,1]和[1,0]。

---

### 5.	算法实现

#### 	5.1	划分训练集和测试机

​		利用sklearn进行数据集的划分:

```python
X_train,X_val,Y_train,Y_val = train_test_split(dataset_X.as_matrix(),
                                                 dataset_Y.as_matrix(),
                                                test_size = 0.2,
                                                random_state = 42)
```

#### 	5.2	定义layer参数和输出

​		首先定义训练数据x和label y:

```python
import tensorflow as tf
x = tf.placeholder(tf.float32,shape = [None,7],name = 'input')
y = tf.placeholder(tf.float32,shape = [None,2],name = 'label')
```

​		定义layer的参数和输出:

```python
weights1 = tf.Variable(tf.random_normal([7,7]),name = 'weights1')
bias1 = tf.Variable(tf.zeros([7]),name = 'bias1')
Wx_plus_b = tf.matmul(x, weights1) + bias1
weights2 = tf.Variable(tf.random_normal([7,2]),name = 'weights2')
bias2 = tf.Variable(tf.zeros([2]),name = 'bias2')
z = tf.matmul(output1,weights2) + bias2
z = tf.nn.dropout(z, keep_prob)
```

​		定义训练器和预测输出:

```python

```

​		训练时，总共进行50次迭代，每5次迭代进行一次交叉验证:

```python
with tf.Session() as sess:
    tf.global_variables_initializer().run()

    for epoch in range(50):
        total_loss = 0.
        for i in range(len(X_train)):
            feed_dict = {x: [X_train[i]],y:[Y_train[i]], keep_prob: 0.9}
            _,loss = sess.run([train_op,cost],feed_dict=feed_dict)
            total_loss +=loss
        print('Epoch: %4d, total loss = %.12f' % (epoch,total_loss))
        if epoch % 5 == 0:
            accuracy = sess.run(acc_op,feed_dict={x:X_val,y:Y_val, keep_prob: 1.0})
            print("Accuracy on validation set: %.9f" % accuracy)

    print('training complete!')
```

​		训练完后，titanic.py在交叉验证集上的正确率为 0.823，提交结果的正确率为0.779。

​				   onehot.py在交叉验证集上正确率为  0.809， 提交结果为0.762

#### 	5.3	模型优化

​		在完成上述呈现的模型后，我发现效果并不是那么好。虽然在验证集上正确率到达了0.82，但是结果表

​	     明模型出现了过拟合的现象。为了解决这个问题，则进行以下工作:

##### 		5.3.1	在隐藏层中进行dropout

​			加入dropout后，模型构建改为:

```
keep_prob = tf.placeholder(tf.float32)
Wx_plus_b = tf.matmul(x, weights1) + bias1
Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)
```

##### 		5.3.2	激活函数和正则化参数

```
output1 = tf.nn.relu(Wx_plus_b)  #加入激活函数

cur_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=z))
tf.add_to_collection('losses', cur_cost)
cost = tf.add_n(tf.get_collection('losses'))    #加入正则化参数
```

​		现在再训练模型，titanic.py在交叉验证集上正确率为0.810，提交后正确率为0.795。

​						onhot.py则为别为0.810，0.813

<img src="C:\Users\banshee\Desktop\ML\20180612221232.png" width="400px" height="400px" />

​								图3:		程序输出结果

---

### 6.	分析与总结

#### 	6.1	训练结果分析

​		在加入dropout，激活函数之前，模型出现了较为严重的过拟合现象。但是在优化模型的过程中，发现

​	     对结果的提升十分不明显，可能的原因是数据集比较粗糙，训练数据较少而且噪声较多，使得神经网络等

​	     对数据比较敏感的模型起不到较好的效果。所以这次实验来看，提升预测结果比较有效的途径是改造数据

​	     本身而不是去修改算法模型，比如在添加了头衔特征后，模型的效果有了明显的变化。由于这次实验的

​	     数据集自身限制，常规算法的表现都不会太高，要使算法的正确率达到一个比较高的值，就需要对数据集

​             进行改造，改造后的数据集因素越多，越符合实际情况，算法的效果就会越好，这一点在onehot.py实现		

​	      的算法效果更好上可以体现出来。

#### 	6.2	难点与创新点

​		这次实验中，主要面对的难点是：

* 数据集中大量的缺失和无法直接用于计算的属性。
* 解决模型产生的过拟合问题

		主要尝试过的创新有:

* 用随机森林算法补全age的缺失值，因为Age对结果的影响非常显著。

* 把提取出来的头衔利用哈希算法映射到100以内的整数值，但是尝试过后发现这种做法效果

  没有把乘客分为贵宾和普通乘客效果好。

* 把类别相关的属性映射成one-hot-array。